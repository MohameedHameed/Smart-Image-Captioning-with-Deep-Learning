{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsnlIhH2AiaC"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1YzxHl_2DVw-396g-e0PxQrCcFZ2aNUHd\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"dataset.zip\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1rX2_7vs7DoprqIvQmMKk8KLLyEdCW4Os\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"dataset1.zip\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "TY_8_6Al3W01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W635q_9LBgJ2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwCA4ejL7p65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QAB9Ja-B0Tr"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"dataset1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94MAF8LttLPn"
      },
      "source": [
        "##Labraries##\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dle5MOK8tUzY"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os\n",
        "from  PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.applications.xception import Xception,preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX9D_sAltVP_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGwF4WTvtXMP"
      },
      "source": [
        "##implementation##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbe5J4PTtbtw"
      },
      "outputs": [],
      "source": [
        "tokens='/content/caption.token.txt'\n",
        "\n",
        "def readFile(path):\n",
        "  file=open(path,'r')\n",
        "  data=file.read()\n",
        "  file.close()\n",
        "  return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KSj5Gd0vmO1"
      },
      "outputs": [],
      "source": [
        "data=readFile(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2soRzijv0Cq"
      },
      "outputs": [],
      "source": [
        "data=data.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ICKtC6UvsBw"
      },
      "outputs": [],
      "source": [
        "\n",
        "data[0].split('\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b07YeyTwv6gi"
      },
      "outputs": [],
      "source": [
        "def analysis(path):\n",
        "  data=readFile(path)\n",
        "  data=data.split('\\n')\n",
        "  descrabtions={}\n",
        "  for record in data:\n",
        "\n",
        "    img,caption =record.split('\\t')\n",
        "    if img[:-2] in descrabtions:\n",
        "      descrabtions[img[:-2]].append(caption)\n",
        "    else:\n",
        "      descrabtions[img[:-2]]=[caption]\n",
        "  return descrabtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrObj3g_wczb"
      },
      "outputs": [],
      "source": [
        "data=analysis(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOll6UuO0ZRc"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXGFJerixJRc"
      },
      "outputs": [],
      "source": [
        "caption=data['2004674713_2883e63c67.jpg'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eebG645QRjCY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAzObFqwxmtB"
      },
      "outputs": [],
      "source": [
        "caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQjOMLVA1JPI"
      },
      "outputs": [],
      "source": [
        "caption=caption.replace('-','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qrlbcDi1Q_B"
      },
      "outputs": [],
      "source": [
        "def preprocesscaption(caption):\n",
        "  caption_list=caption.split()\n",
        "  punct=str.maketrans('','',string.punctuation)\n",
        "  caption_list=[word.lower() for word  in caption_list if len(word)>1 and (word.isalpha())]\n",
        "  caption_list=[word.translate(punct) for word in caption_list]\n",
        "  caption_list\n",
        "  return ' '.join(caption_list)\n",
        "\n",
        "def clean_text(data):\n",
        "  for img,captions in data.items():\n",
        "    for index,caption in enumerate(captions):\n",
        "     data[img][index]=preprocesscaption(caption)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0CX5sNJ4aUb"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LosZeb581YgW"
      },
      "outputs": [],
      "source": [
        "clean_captions=clean_text(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQv_tq_l4Bdp"
      },
      "outputs": [],
      "source": [
        "clean_captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44nyWbKx4ClP"
      },
      "outputs": [],
      "source": [
        "clean_captions['2096771662_984441d20d.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdzqyAMT6Azi"
      },
      "outputs": [],
      "source": [
        "def gentrate_repository(data):\n",
        "\n",
        "  repository_vocab=set()\n",
        "  repository_vocab.update(['hello','world','hello'])\n",
        "\n",
        "  repository_vocab\n",
        "\n",
        "  for img in data.keys():\n",
        "    for caption in data[img]:\n",
        "      repository_vocab.update(caption.split())\n",
        "  return repository_vocab\n",
        "\n",
        "def write_file(path,data):\n",
        "   lines=[]\n",
        "   for img,captions in data.items():\n",
        "    for caption in captions:\n",
        "      lines.append(img+'\\t'+caption)\n",
        "   data='\\n'.join(lines)\n",
        "   file=open(path,'w')\n",
        "   file.write(data)\n",
        "   file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flw2KLdY8PIU"
      },
      "outputs": [],
      "source": [
        "repository_vocab=gentrate_repository(clean_captions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJHm8Yb19DNo"
      },
      "outputs": [],
      "source": [
        "len(repository_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xUFksBW9GGj"
      },
      "outputs": [],
      "source": [
        "repository_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ss8F7wb9nOu"
      },
      "outputs": [],
      "source": [
        "write_file('/content/clean_tokens.txt',clean_captions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ItYPm0D_aEz"
      },
      "outputs": [],
      "source": [
        "path_images='/content/dataset/images'\n",
        "\n",
        "os.listdir(path_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRyC0gwqCdLQ"
      },
      "outputs": [],
      "source": [
        "imagefile=path_images+'/'+os.listdir(path_images)[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDYw8M1nIoja"
      },
      "outputs": [],
      "source": [
        "imagefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZC0dYNuIp9x"
      },
      "outputs": [],
      "source": [
        "img=Image.open(imagefile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSGmu-VILzTP"
      },
      "outputs": [],
      "source": [
        "model=Xception(include_top=False,pooling='avg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka4zaWp6I8eS"
      },
      "outputs": [],
      "source": [
        "def feature_extraction(path,model):\n",
        "  features={}\n",
        "  for imageName in os.listdir(path):\n",
        "    completepath=path_images+'/'+imageName\n",
        "    img=Image.open(completepath)\n",
        "    img=img.resize((299,299))\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "    img=img/127.5\n",
        "    img=img-1.0\n",
        "    feature=model.predict(img)\n",
        "    features[imageName]=feature\n",
        "\n",
        "  return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtOKTp2dL0uf"
      },
      "outputs": [],
      "source": [
        "#f=feature_extraction(path_images,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5MWmymZLgzq"
      },
      "outputs": [],
      "source": [
        "\n",
        "#pickle.dump(f,open('/content/imgs_features.bin','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJM5xv9CJCBP"
      },
      "outputs": [],
      "source": [
        "f=pickle.load(open('/content/dataset1/imgs_features.bin','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaR0mKJMLF1c"
      },
      "outputs": [],
      "source": [
        "f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path='/content/caption.trainImages.txt'\n",
        "clean_tokens_path='/content/clean_tokens.txt'\n",
        "feature_path='/content/dataset1/imgs_features.bin'"
      ],
      "metadata": {
        "id": "PVBPdhnmsnNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadimages(path):\n",
        "  data=readFile(path)\n",
        "  data=data.split('\\n')\n",
        "  return data\n",
        "\n",
        "def load_tokens(path,images):\n",
        "  data=readFile(path)\n",
        "  lines=data.split('\\n')\n",
        "  tokens={}\n",
        "  for line in lines:\n",
        "    img,caption=line.split('\\t')\n",
        "    if img in images:\n",
        "      if img not in tokens:\n",
        "        tokens[img]=[]\n",
        "      tokens[img].append('<start> ' +caption+ ' <end>')\n",
        "\n",
        "  return tokens\n",
        "\n",
        "def load_features(path,images):\n",
        "  features=pickle.load(open(path,'rb'))\n",
        "  selected_features=[{image:features[image]} for image in images  if image in features]\n",
        "  return selected_features\n"
      ],
      "metadata": {
        "id": "zuu74x8Es5fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image=loadimages(train_images_path)"
      ],
      "metadata": {
        "id": "d3ubj4TZtHoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image"
      ],
      "metadata": {
        "id": "6tNEfK9stKA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens=load_tokens(clean_tokens_path,train_image)"
      ],
      "metadata": {
        "id": "ZjSpMq_0tKyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens"
      ],
      "metadata": {
        "id": "McVY6x3lu9ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features=load_features(feature_path,train_image)"
      ],
      "metadata": {
        "id": "if856wkFvIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6aztGqHf-Cqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features"
      ],
      "metadata": {
        "id": "E7G4suf29ClH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_captions(data):\n",
        "\n",
        "  captionss=[]\n",
        "  for captions in train_tokens.values():\n",
        "    for caption in captions:\n",
        "      captionss.append(caption)\n",
        "  return captionss\n",
        "\n",
        "def create_tokenizer(captionss):\n",
        "  tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(captionss)\n",
        "  return tokenizer\n",
        "def longestcaptions(captionss):\n",
        "  return max(len(caption.split()) for caption in captionss)"
      ],
      "metadata": {
        "id": "DQDW39_i-DUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captionss=fetch_captions(train_tokens)\n",
        "tokenizer=create_tokenizer(captionss)"
      ],
      "metadata": {
        "id": "23vYCmtL_F8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captionss"
      ],
      "metadata": {
        "id": "a6fGu5NH-AzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "TtBe6cvc_AC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "jMrgkjm2_opm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "id": "Iyp3gN1d_whG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([train_tokens['2256320794_0286c31bfa.jpg'][0]])[0]"
      ],
      "metadata": {
        "id": "hvT3M7QY_2Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_cap=longestcaptions(captionss)"
      ],
      "metadata": {
        "id": "kYU96byS__zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_cap"
      ],
      "metadata": {
        "id": "Gj5WEeAzAyNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq=train_tokens['2256320794_0286c31bfa.jpg'][0].split()"
      ],
      "metadata": {
        "id": "qPvOauWjA9Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq"
      ],
      "metadata": {
        "id": "3qMmBkszBV1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word_index in range(len(seq)):\n",
        "  in_seq=seq[:word_index]\n",
        "  out_w=seq[word_index]\n",
        "  print(in_seq,out_w)"
      ],
      "metadata": {
        "id": "6D8q2vOxBfQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bulid_sequences(tokenizer,max_cap,vocab_size,feature,caption):\n",
        "  input1,input2,output=[],[], []\n",
        "  for cap in caption:\n",
        "    seq=tokenizer.texts_to_sequences([cap])[0]\n",
        "\n",
        "    for word_index in range(len(seq)):\n",
        "      in_seq=seq[:word_index]\n",
        "      in_seq=pad_sequences([in_seq],maxlen=max_cap,padding='post')[0]\n",
        "      out_w=seq[word_index]\n",
        "      out_w=to_categorical([out_w],num_classes=vocab_size)[0]\n",
        "      input1.append(feature)\n",
        "      input2.append(in_seq)\n",
        "      output.append(out_w)\n",
        "  return np.array(input1),np.array(input2),np.array(output)\n",
        "def datagenrator(tokenizer, features, train_tokens, max_cap, vocab_size, data):\n",
        "    while True:\n",
        "        for img, caption in data.items():\n",
        "            if img in features:\n",
        "                feature = features[img][0]\n",
        "                input1, input2, output = bulid_sequences(tokenizer, max_cap, vocab_size, feature, caption)\n",
        "                yield ({\"input_image\": input1, \"input_sequence\": input2}, output)\n",
        "\n"
      ],
      "metadata": {
        "id": "Yx8EZ6VPB-hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[in_img,in_seq],_out_w]=next(datagenrator(tokenizer,f,train_tokens,max_cap,vocab_size,train_tokens))"
      ],
      "metadata": {
        "id": "YS1VegkjC-xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in_img.shape,in_seq.shape,_out_w.shape"
      ],
      "metadata": {
        "id": "-FtEJfukEP-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#featuresize=in_img.shape[1]"
      ],
      "metadata": {
        "id": "ozxTCT5NM4Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bulidModel(num_fatures,longestcaptions,vocab_size):\n",
        "  #FeedForward model\n",
        "  inputs_img=Input(shape=(num_fatures,),name=\"input_image\")\n",
        "  fe1=Dropout(0.5)(inputs_img)\n",
        "  fe2=Dense(256,activation='relu')(fe1)\n",
        "  #LSTM model -text\n",
        "  inputts_seq=Input(shape=(longestcaptions,), name=\"input_sequence\")\n",
        "  se1=Embedding(vocab_size,256,mask_zero=True)(inputts_seq)\n",
        "  se2=Dropout(0.5)(se1)\n",
        "  se3=LSTM(256, use_cudnn=False)(se2)\n",
        "\n",
        "\n",
        "  #marge\n",
        "  marged_model=add([fe2,se3])\n",
        "  finalmodel=Dense(256,activation='relu')(marged_model)\n",
        "  outputs=Dense(vocab_size,activation='softmax')(finalmodel)\n",
        "  model=Model(inputs=[inputs_img,inputts_seq],outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "  return model"
      ],
      "metadata": {
        "id": "qmZp4D48Gvh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=bulidModel(2048,max_cap,vocab_size)\n"
      ],
      "metadata": {
        "id": "oz4seKqDI48i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: datagenrator(tokenizer, f, train_tokens, max_cap, vocab_size, train_tokens),\n",
        "    output_signature=(\n",
        "        {\n",
        "            \"input_image\": tf.TensorSpec(shape=(None, 2048), dtype=tf.float32),\n",
        "            \"input_sequence\": tf.TensorSpec(shape=(None, max_cap), dtype=tf.int32),\n",
        "        },\n",
        "        tf.TensorSpec(shape=(None, vocab_size), dtype=tf.float32),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "VK9keRj9Qnps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#geneartor=datagenrator(tokenizer,f,train_tokens,max_cap,vocab_size,train_tokens)\n",
        "model.fit(dataset,epochs=10,steps_per_epoch=len(train_tokens),verbose=1)\n",
        "model.save('model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZmc1kyNM-Kz",
        "outputId": "51f38cf6-28f8-46e6-d513-6e9fd0d60d72"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - loss: 2.1171\n",
            "Epoch 2/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 2.0338\n",
            "Epoch 3/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - loss: 1.9686\n",
            "Epoch 4/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - loss: 1.9076\n",
            "Epoch 5/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - loss: 1.8515\n",
            "Epoch 6/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - loss: 1.8160\n",
            "Epoch 7/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 1.7848\n",
            "Epoch 8/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 1.7306\n",
            "Epoch 9/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 1.6825\n",
            "Epoch 10/10\n",
            "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - loss: 1.6604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Z1tsp0-DNzgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Testing##\n",
        "```\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PMhICelYWA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imgfeature_extraction(path,model):\n",
        "  try:\n",
        "      img=Image.open(path)\n",
        "\n",
        "      img=img.resize((299,299))\n",
        "      img=np.expand_dims(img,axis=0)\n",
        "      img=img/127.5\n",
        "      img=img-1.0\n",
        "      feature=model.predict(img)\n",
        "\n",
        "      return feature\n",
        "  except:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "knjEhRh-V7UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getword(indx,tokenizer):\n",
        "  return list(tokenizer.word_index)[indx-1]"
      ],
      "metadata": {
        "id": "rIcUAPZOWilt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genearte_caption(model,tokenizer,imgFeature,longestcaptions):\n",
        "  in_text='start'\n",
        "  for i in range(longestcaptions):\n",
        "    seq=tokenizer.texts_to_sequences([in_text])[0]\n",
        "    seq=pad_sequences([seq],maxlen=longestcaptions,padding='post')\n",
        "    yhat=model.predict([imgFeature,seq],verbose=0)\n",
        "    indx=np.argmax(yhat)\n",
        "    word_index=getword(indx,tokenizer)\n",
        "    if word_index=='end':\n",
        "      break\n",
        "    in_text+=' '+word_index\n",
        "  return in_text[6:]"
      ],
      "metadata": {
        "id": "bQX-aH8bWoFh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZuyemH1izcL"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model=Xception(include_top=False,pooling='avg')\n",
        "img='/content/1.jpg'\n",
        "imgFeature=imgfeature_extraction(img,cnn_model)\n",
        "imgFeature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LqcuTp4Xysr",
        "outputId": "cfca5699-a268-4fd7-a737-839787b4c739"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06515392, 0.        , 0.02060204, ..., 0.        , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap_model=load_model('/content/model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODXqmeiBav1y",
        "outputId": "0847f0e0-e66c-48d9-ad08-2ff069884816"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py:210: UserWarning: Model doesn't support `jit_compile=True`. Proceeding with `jit_compile=False`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle.dump(tokenizer,open('/content/tokenizer.bin','wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "CuJSWdtYY3hj",
        "outputId": "bc0255b2-5986-48ed-c0b5-ff3f72d9c98d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-babdd3175cce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/tokenizer.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=pickle.load(open('/content/tokenizer.bin','rb'))\n"
      ],
      "metadata": {
        "id": "vjsmmGIkZLDj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPQyTI78jFAv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genearte_caption(cap_model,tokenizer,imgFeature,33)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TAyLIvHZd0Z9",
        "outputId": "686332b6-5bb1-497f-8221-6de0fdd258d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'brown dog is running through the grass'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iEZGM6Cd3cz"
      },
      "execution_count": 247,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}